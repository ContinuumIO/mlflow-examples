{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow Training Demo\n",
    "\n",
    "In this demo, we will be creating and comparing a number of models for predicting the housing costs in California using [xgboost.XGBRegressor](https://xgboost.readthedocs.io/en/stable/python/python_api.html).  We perform a naive search of the hyper-parameter space in order to determine the optimal values.\n",
    "\n",
    "The data pertains to the houses found in a given California district and some summary stats about them based on the 1990 census data. Be warned the data aren't cleaned so there are some preprocessing steps required! The columns are as follows, their names are pretty self explanitory:\n",
    "\n",
    "**Input Variables**:\n",
    "* longitude\n",
    "* latitude\n",
    "* housing median age\n",
    "* total rooms\n",
    "* total bedrooms\n",
    "* population\n",
    "* households\n",
    "* median income\n",
    "* ocean proximity\n",
    "\n",
    "**Output variable (based on sensory data)**:\n",
    "\n",
    "* median house value\n",
    "\n",
    "The results of the model training runs are tracked in an MLflow experiment. The best performing model is then registered in the model registry and set to the `Production` stage for usage.\n",
    "\n",
    "> This is notebook is based on `train.py` from the MLflow example [xgboost_sklearn](https://github.com/mlflow/mlflow/tree/master/examples/xgboost/xgboost_sklearn)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking Setup\n",
    "\n",
    "Create our experiment to track all our model training runs in.\n",
    "\n",
    "* This experiment is used across runs of the notebook and will not be recreated if it already exists.\n",
    "* The name of the experiment is defined as an anaconda project variable located within `anaconda-project.yml`.\n",
    "    * The variable name is `MLFLOW_EXPERIMENT_NAME`, and the default value is `demo_california_housing_prices`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T20:44:17.327535Z",
     "start_time": "2023-10-20T20:44:16.260379Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.environment import init\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "experiment_id, client = init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T20:44:20.042185Z",
     "start_time": "2023-10-20T20:44:19.320481Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model Training Function\n",
    "\"\"\"\n",
    "\n",
    "from src.data import DataSet\n",
    "from pydantic.main import BaseModel\n",
    "from mlflow_adsp import create_unique_name\n",
    "import os\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import mlflow.xgboost\n",
    "\n",
    "# Enable MLflow auto logging of xgboost\n",
    "mlflow.xgboost.autolog()\n",
    "\n",
    "\n",
    "class HyperParameters(BaseModel):\n",
    "    n_estimators: int\n",
    "    max_depth: int\n",
    "    reg_lambda: float\n",
    "    gamma: float\n",
    "    early_stopping_rounds: int\n",
    "\n",
    "\n",
    "def train(ds: DataSet, parameters: HyperParameters) -> str:\n",
    "    # Start the MLflow run to track the model training.\n",
    "    with mlflow.start_run(run_name=create_unique_name(name=os.environ[\"MLFLOW_EXPERIMENT_NAME\"])) as run:\n",
    "        # https://xgboost.readthedocs.io/en/stable/python/python_api.html\n",
    "        regressor = xgb.XGBRegressor(\n",
    "            n_estimators=parameters.n_estimators,\n",
    "            max_depth=parameters.max_depth,\n",
    "            reg_lambda=parameters.reg_lambda,\n",
    "            gamma=parameters.gamma,\n",
    "            early_stopping_rounds=parameters.early_stopping_rounds,\n",
    "        )\n",
    "        regressor.fit(X=ds.X_train, y=ds.y_train, eval_set=[(ds.X_test, ds.y_test)], verbose=False)\n",
    "\n",
    "        # Return the run_id for training run comparisons.\n",
    "        return run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T20:44:25.018407Z",
     "start_time": "2023-10-20T20:44:21.183415Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.data import prepare_data\n",
    "from mlflow.entities import Run\n",
    "\n",
    "DATA_SET_FILENAME: str = \"datasets/housing.csv\"\n",
    "\n",
    "data_set: DataSet = prepare_data(csv_url=DATA_SET_FILENAME)\n",
    "parameters = HyperParameters(n_estimators=18, max_depth=10, reg_lambda=1, gamma=0, early_stopping_rounds=10)\n",
    "\n",
    "run_id: str = train(ds=data_set, parameters=parameters)\n",
    "run: Run = client.search_runs([experiment_id], f\"attributes.run_id = '{run_id}'\")[0]\n",
    "\n",
    "print(f\"Run ID: {run_id}\")\n",
    "print(run.data.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform a naive search of the hyperparameter space\n",
    "\n",
    "We will naively review model performance at specific internals across the solution space.  There are many optimization functions, which can be leveraged based on business needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T20:45:25.695425Z",
     "start_time": "2023-10-20T20:45:25.692621Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "\n",
    "def get_best_run(client: MlflowClient, experiment_id, runs: list[str]) -> tuple[Optional[Run], dict]:\n",
    "    _inf = np.finfo(np.float64).max\n",
    "\n",
    "    best_metrics: dict = {\n",
    "        \"validation_0-rmse\": _inf,\n",
    "    }\n",
    "    best_run: Optional[Run] = None\n",
    "\n",
    "    for run_id in runs:\n",
    "        # find the best run, log its metrics as the final metrics of this run.\n",
    "        run: Run = client.search_runs([experiment_id], f\"attributes.run_id = '{run_id}'\")[0]\n",
    "        if (\n",
    "            \"validation_0-rmse\" in run.data.metrics\n",
    "            and run.data.metrics[\"validation_0-rmse\"] < best_metrics[\"validation_0-rmse\"]\n",
    "        ):\n",
    "            best_metrics = run.data.metrics\n",
    "            best_run = run\n",
    "\n",
    "    return best_run, best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T20:46:35.402775Z",
     "start_time": "2023-10-20T20:45:26.226144Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "runs: list[str] = []\n",
    "\n",
    "for i in trange(3, 9):\n",
    "    n_estimators: int = i * 2 + 1\n",
    "    for j in range(3, 9):\n",
    "        max_depth: int = j + 3\n",
    "        data_set: DataSet = prepare_data(csv_url=DATA_SET_FILENAME)\n",
    "        parameters = HyperParameters(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            reg_lambda=1,\n",
    "            gamma=0,\n",
    "            early_stopping_rounds=10,\n",
    "        )\n",
    "        run_id: str = train(ds=data_set, parameters=parameters)\n",
    "        runs.append(run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find and register the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review the runs for the best performing model and add it to the model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T20:46:41.861413Z",
     "start_time": "2023-10-20T20:46:41.205208Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mlflow.entities.model_registry import ModelVersion\n",
    "\n",
    "(best_run, metrics) = get_best_run(client=client, experiment_id=experiment_id, runs=runs)\n",
    "\n",
    "print(f\"Run ID: {best_run.info.run_id}\")\n",
    "print(f\"Report: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T20:46:54.839509Z",
     "start_time": "2023-10-20T20:46:54.789536Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.mlflow_helpers import register_best_model\n",
    "\n",
    "model_version: ModelVersion = register_best_model(client=client, run=best_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Promote the latest model to the `Production` stage for usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T20:46:57.759318Z",
     "start_time": "2023-10-20T20:46:57.715816Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_version: ModelVersion = client.transition_model_version_stage(\n",
    "    name=os.environ[\"MLFLOW_EXPERIMENT_NAME\"],\n",
    "    version=model_version.version,\n",
    "    stage=\"Production\",\n",
    "    archive_existing_versions=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we're ready to create an API Deployment with our Production model with the following steps:\n",
    "\n",
    "1. Select \"Deploy\" in the top right of this AE5 Screen.\n",
    "2. Name the deployment - We will be creating two deployments in this demo so it can be helpful to include \"API\" in the name.\n",
    "3. Set the deployment command to 'host-production-model-rest-api'.\n",
    "4. Set the URL to 'Static' and ensure the URL matches the 'endpoint-url' in the 'consume-rest-api.ipynb' notebook.\n",
    "5. Set the privacy to \"Public\".\n",
    "6. Deploy!\n",
    "\n",
    "And in a few moments we will have an API that we can use to make predictions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
