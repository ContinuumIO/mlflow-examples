{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow Training Demo\n",
    "\n",
    "Creates a model for predicting the quality of wine using [xgboost.XGBRegressor](https://xgboost.readthedocs.io/en/stable/python/python_api.html).  We perform a naive search of the hyperparameter space in order to determine the optimal values.\n",
    "\n",
    "The dataset contains the chemical properties of many different wines made from the Vinho Verde grape, a native grape of Portugal.\n",
    "The data we will be primarily using will be the white wine variety of Vinho Verde, however we also can set up an additional MLFlow experiment with red wine data.\n",
    "\n",
    "**Input Variables**:\n",
    "1. fixed acidity (tartaric acid - g / dm^3\n",
    "2. volatile acidity (acetic acid - g / dm^3)\n",
    "3. citric acid (g / dm^3)\n",
    "4. residual sugar (g / dm^3)\n",
    "5. chlorides (sodium chloride - g / dm^3\n",
    "6. free sulfur dioxide (mg / dm^3)\n",
    "7. total sulfur dioxide (mg / dm^3)\n",
    "8. density (g / cm^3)\n",
    "9. pH\n",
    "10. sulphates (potassium sulphate - g / dm3)\n",
    "11. alcohol (% by volume)\n",
    "\n",
    "**Output variable (based on sensory data)**:\n",
    "\n",
    "12. quality (score between 0 and 10)\n",
    "\n",
    "The results of the model training runs are tracked in an MLflow experiment. The best performing model is then registered in the model registry and set to the `Production` stage for usage.\n",
    "\n",
    "> This is notebook is based on `train.py` from the MLflow example [xgboost_sklearn](https://github.com/mlflow/mlflow/tree/master/examples/xgboost/xgboost_sklearn).\n",
    "\n",
    "Attribution\n",
    "* The data set used in this example is from http://archive.ics.uci.edu/ml/datasets/Wine+Quality.\n",
    "* P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "* Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking Setup\n",
    "\n",
    "Create our experiment to track all our model training runs in.\n",
    "\n",
    "* This experiment is used across runs of the notebook and will not be recreated if it already exists.\n",
    "* The name of the experiment is defined as an anaconda project variable located within `anaconda-project.yml`.\n",
    "    * The variable name is `MLFLOW_EXPERIMENT_NAME`, and the default value is `demo_sklearn_elasticnet_wine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.environment import init\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "experiment_id, client = init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model Training Function\n",
    "\"\"\"\n",
    "\n",
    "from src.data import DataSet\n",
    "from pydantic.main import BaseModel\n",
    "from mlflow_adsp import create_unique_name\n",
    "import os\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import mlflow.xgboost\n",
    "\n",
    "\n",
    "class HyperParameters(BaseModel):\n",
    "    n_estimators: int\n",
    "    max_depth: int\n",
    "    reg_lambda: float\n",
    "    gamma: float\n",
    "    early_stopping_rounds: int\n",
    "\n",
    "\n",
    "def train(ds: DataSet, parameters: HyperParameters) -> str:\n",
    "    # Start the MLflow run to track the model training.\n",
    "    with mlflow.start_run(run_name=create_unique_name(name=os.environ[\"MLFLOW_EXPERIMENT_NAME\"])) as run:\n",
    "        # Enable MLflow logging\n",
    "        mlflow.xgboost.autolog()\n",
    "\n",
    "        # https://xgboost.readthedocs.io/en/stable/python/python_api.html\n",
    "        regressor = xgb.XGBRegressor(\n",
    "            n_estimators=parameters.n_estimators,\n",
    "            max_depth=parameters.max_depth,\n",
    "            reg_lambda=parameters.reg_lambda,\n",
    "            gamma=parameters.gamma,\n",
    "            early_stopping_rounds=parameters.early_stopping_rounds,\n",
    "        )\n",
    "        regressor.fit(X=ds.X_train, y=ds.y_train, eval_set=[(ds.X_test, ds.y_test)], verbose=False)\n",
    "\n",
    "        # Return the run_id for training run comparisons.\n",
    "        return run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.data import prepare_data\n",
    "from mlflow.entities import Run\n",
    "\n",
    "DATA_SET_FILENAME: str = \"datasets/housing.csv\"\n",
    "\n",
    "data_set: DataSet = prepare_data(csv_url=DATA_SET_FILENAME)\n",
    "parameters = HyperParameters(n_estimators=18, max_depth=10, reg_lambda=1, gamma=0, early_stopping_rounds=10)\n",
    "\n",
    "run_id: str = train(ds=data_set, parameters=parameters)\n",
    "stand_alone_run: Run = client.search_runs([experiment_id], f\"attributes.run_id = '{run_id}'\")[0]\n",
    "\n",
    "print(f\"Run ID: {run_id}\")\n",
    "print(stand_alone_run.data.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform a naive search of the hyperparameter space\n",
    "\n",
    "We will naively review model performance at specific internals across the solution space.  There are many optimization functions, which can be leveraged based on business needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "\n",
    "def get_best_run(client: MlflowClient, experiment_id, runs: list[str]) -> tuple[Optional[Run], dict]:\n",
    "    _inf = np.finfo(np.float64).max\n",
    "\n",
    "    best_metrics: dict = {\n",
    "        \"validation_0-rmse\": _inf,\n",
    "    }\n",
    "    best_run: Optional[Run] = None\n",
    "\n",
    "    for run_id in runs:\n",
    "        # find the best run, log its metrics as the final metrics of this run.\n",
    "        run: Run = client.search_runs([experiment_id], f\"attributes.run_id = '{run_id}'\")[0]\n",
    "        if (\n",
    "            \"validation_0-rmse\" in run.data.metrics\n",
    "            and run.data.metrics[\"validation_0-rmse\"] < best_metrics[\"validation_0-rmse\"]\n",
    "        ):\n",
    "            best_metrics = run.data.metrics\n",
    "            best_run = run\n",
    "\n",
    "    return best_run, best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "runs: list[str] = []\n",
    "\n",
    "for i in trange(3, 9):\n",
    "    n_estimators: int = i * 2 + 1\n",
    "    for j in range(3, 9):\n",
    "        max_depth: int = j + 3\n",
    "        data_set: DataSet = prepare_data(csv_url=DATA_SET_FILENAME)\n",
    "        parameters = HyperParameters(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            reg_lambda=1,\n",
    "            gamma=0,\n",
    "            early_stopping_rounds=10,\n",
    "        )\n",
    "        run_id: str = train(ds=data_set, parameters=parameters)\n",
    "        runs.append(run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find and register the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review the runs for the best performing model and add it to the model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mlflow.entities.model_registry import ModelVersion\n",
    "\n",
    "(best_run, metrics) = get_best_run(client=client, experiment_id=experiment_id, runs=runs)\n",
    "\n",
    "print(f\"Run ID: {best_run.info.run_id}\")\n",
    "print(f\"Report: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from wine_quality.mlflow_helpers import register_best_model\n",
    "\n",
    "model_version: ModelVersion = register_best_model(client=client, run=best_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Promote the latest model to the `Production` stage for usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_version: ModelVersion = client.transition_model_version_stage(\n",
    "    name=os.environ[\"MLFLOW_EXPERIMENT_NAME\"],\n",
    "    version=model_version.version,\n",
    "    stage=\"Production\",\n",
    "    archive_existing_versions=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we're ready to create an API Deployment with our Production model with the following steps:\n",
    "\n",
    "1. Select \"Deploy\" in the top right of this AE5 Screen.\n",
    "2. Name the deployment - We will be creating two deployments in this demo so it can be helpful to include \"API\" in the name.\n",
    "3. Set the deployment command to 'host-production-model-rest-api'.\n",
    "4. Set the URL to 'Static' and ensure the URL matches the 'endpoint-url' in the 'consume-rest-api.ipynb' notebook.\n",
    "5. Set the privacy to \"Public\".\n",
    "6. Deploy!\n",
    "\n",
    "And in a few moments we will have an API that we can use to make predictions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) [default]",
   "language": "python",
   "name": "anaconda-project-default-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
