{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Diffusion |  MLFlow Driven Parallelism within ADSP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This solution leverages [https://keras.io/api/keras_cv/models/stable_diffusion/](https://keras.io/api/keras_cv/models/stable_diffusion/) to generate imagery from textual prompts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "Image processing occurs in batches.  If executing locally the batches are processed in serial, when running within ADSP these are processed in parallel.\n",
    "\n",
    "Parallel execution occurs within ADSP `run-once` jobs associcated with the project.  The scheduler will block until all jobs have completed.\n",
    "\n",
    "### Workflow Diagram\n",
    "![Workflow Overview](../assets/workflow-overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "1. Download the example.\n",
    "2. Ensure the variable `AE_MLFLOW_EXPERIMENT_NAME` within the `anaconda-project.yml` is updated appropriately.\n",
    "3. Upload the project to ADSP.  If you're already here, great!  Just skip this and keep going. :)\n",
    "    > ae5 project upload .\n",
    "4. Ensure you have the below AE5 secrets defined, or uncommented and added to the `anaconda-project.yml` file.\n",
    "    \n",
    "    | Variable              |\n",
    "    |-----------------------|\n",
    "    | AE5_HOSTNAME          |\n",
    "    | AE5_USERNAME          |\n",
    "    | AE5_PASSWORD          |\n",
    "    | ADSP_WORKER_MAX       |\n",
    "    | MLFLOW_TRACKING_URI   |\n",
    "    | MLFLOW_REGISTRY_URI   |\n",
    "    | MLFLOW_TRACKING_TOKEN |\n",
    "\n",
    "5. Start a project session and allow conda to complete dependency installation. \n",
    "   1. Perform the one time ADSP account setup for Keras (see below) if this has not yet been completed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Setup for parallel processing within ADSP\n",
    "\n",
    "Since this makes changes to your user account environment they must be perfomed from an interactive session.  This change needs to be done only once per account.  The change affects all projects the user launches.\n",
    "\n",
    "#### Account Level One Time Setup\n",
    "\n",
    "Within `/opt/continuum` create a symbolic link `.keras` to --> `user/home/.keras`\n",
    "\n",
    "> cd /opt/continuum && ln -s user/home/.keras .keras\n",
    "\n",
    "This allows keras to download and cache models, checkpoints, datasets, etc between all instances.\n",
    "If this step is not completed each time Keras executes in a new session, or job it will re-download these external resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the workflow\n",
    "\n",
    "Ensure:\n",
    " 1. We load AE5 secrets\n",
    " 2. That we have set our experiment name for reporting.\n",
    "     1. See notes in anaconda-project.xml around MLFlow project naming control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from anaconda.enterprise.server.common.sdk import load_ae5_user_secrets\n",
    "from mlflow_adsp import upsert_experiment\n",
    "\n",
    "load_ae5_user_secrets()\n",
    "mlflow.set_experiment(experiment_id=upsert_experiment())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Our Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prompt to use for image generation.\n",
    "prompt: str = \"flower\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "# The base data directory that requests are stored in.\n",
    "data_base_dir: str = \"data\"\n",
    "\n",
    "# Number of total images to generate.\n",
    "total_batch_size: int = 5\n",
    "\n",
    "# Number of images to generate per worker invocation.\n",
    "per_worker_batch_size: int = 1\n",
    "\n",
    "# Number of Steps\n",
    "num_steps: int = 50\n",
    "\n",
    "# Optional Seed\n",
    "seed: Optional[float] = None\n",
    "\n",
    "# Image Width\n",
    "image_width: int = 192\n",
    "\n",
    "# Image Height\n",
    "image_height: int = 192\n",
    "\n",
    "# The name of the run.\n",
    "run_name: str = \"workflow-step-process-data\"\n",
    "\n",
    "# The backend to use for workers.\n",
    "backend: str = \"adsp\"  # adsp | local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start A New MLFlow Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import ActiveRun\n",
    "from mlflow_adsp import create_unique_name\n",
    "\n",
    "workflow_run: ActiveRun = mlflow.start_run(run_name=create_unique_name(name=run_name))\n",
    "\n",
    "# The MLFlow Run ID\n",
    "run_id: str = workflow_run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare The Processing Job Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "from pathlib import Path\n",
    "\n",
    "# Generate our internal tracking request ID\n",
    "request_id: str = str(uuid.uuid4())\n",
    "\n",
    "# Store our prompt to the shared data cache for all the workers to load.\n",
    "base_path: Path = Path(data_base_dir) / request_id\n",
    "base_path.mkdir(parents=True, exist_ok=True)\n",
    "with open(file=(base_path / \"prompt.txt\").as_posix(), mode=\"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Step 1 - Prepare Worker Environment\n",
    "\n",
    "Below we launch step 1 `prepare_worker_environment` locally and allow it to build and prepare the worker environment.\n",
    "\n",
    "The this allows the jobs to load the runtime environment quickly when starting and avoids having to perform rebuild a conda envirnment prior to execution.  It will not recreate the environment on subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from mlflow_adsp import Step\n",
    "\n",
    "step = Step(\n",
    "    entry_point=\"prepare_worker_environment\",\n",
    "    parameters={\"backend\": backend},\n",
    "    run_name=create_unique_name(name=\"workflow-step-prepare-worker-environment\"),\n",
    "    synchronous=True,\n",
    "    backend=\"local\",\n",
    ")\n",
    "mlflow.projects.run(**step.dict(by_alias=False))\n",
    "\n",
    "# Alternatively a direct mlflow run invocation would be:\n",
    "# mlflow.projects.run({\n",
    "#     \"entry_point\": \"prepare_worker_environment\",\n",
    "#     \"parameters\": {\"backend\": backend},\n",
    "#     \"run_name\": create_unique_name(name=\"workflow-step-prepare-worker-environment\"),\n",
    "#     \"uri\": \".\",\n",
    "#     \"env_manager\": \"local\"\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Step 2 - [Batch Processing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the batch request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import math\n",
    "\n",
    "worker_count: int = math.ceil(total_batch_size / per_worker_batch_size)\n",
    "print(f\"Number of jobs needed to complete request: {worker_count}\")\n",
    "\n",
    "steps: List[Step] = []\n",
    "for _ in range(worker_count):\n",
    "    step: Step = Step(\n",
    "        entry_point=\"process_data\",\n",
    "        parameters={\n",
    "            \"request_id\": request_id,\n",
    "            \"data_base_dir\": data_base_dir,\n",
    "            \"batch_size\": per_worker_batch_size,\n",
    "            \"image_width\": image_width,\n",
    "            \"image_height\": image_height,\n",
    "            \"num_steps\": num_steps,\n",
    "            \"seed\": seed,\n",
    "        },\n",
    "        run_name=create_unique_name(name=\"workflow-step-process-data\"),\n",
    "        backend=backend,\n",
    "        backend_config={\"resource_profile\": \"large\"},\n",
    "        synchronous=True if backend == \"local\" else False,  # Force to serial processing if running locally.\n",
    "    )\n",
    "    steps.append(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the batch and wait for completion\n",
    "\n",
    "The scheduler will block until execution of the batch is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from mlflow_adsp import Job, Scheduler\n",
    "\n",
    "# submit jobs\n",
    "print(\"Launching processing steps ...\")\n",
    "adsp_jobs: List[Job] = Scheduler().process_work_queue(steps=steps)\n",
    "print(\"Work complete.\")\n",
    "\n",
    "# End the run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_images(images):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(len(images)):\n",
    "        ax = plt.subplot(1, len(images), i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look up and download all the png files added to the runs in order to build our gallery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "from PIL import Image\n",
    "\n",
    "# Review job status\n",
    "mlflow_client = MlflowClient()\n",
    "\n",
    "images = []\n",
    "\n",
    "for job in adsp_jobs:\n",
    "    print(f\"Job ID: {job.id}, Status: {job.last_status}, Number of executions: {len(job.runs)}\")\n",
    "\n",
    "    # If a job failed, then it was ran more than once.  If successful the last run is the one that successed and will be loaded.\n",
    "    mlflow_run_id: str = job.runs[-1].mlflow_run_id\n",
    "\n",
    "    # Get the list of artifacts for the run.\n",
    "    artifacts = mlflow_client.list_artifacts(mlflow_run_id)\n",
    "\n",
    "    # We have a few different types but we only want the images for the gallery.\n",
    "    images_metadata = [\n",
    "        artifact for artifact in mlflow_client.list_artifacts(mlflow_run_id) if artifact.path.endswith(\".png\")\n",
    "    ]\n",
    "\n",
    "    # Download the image and add it to our gallery\n",
    "    for metadata in images_metadata:\n",
    "        artifact_uri = f\"runs:/{mlflow_run_id}/{metadata.path}\"\n",
    "        image: Image = mlflow.artifacts.load_image(artifact_uri)\n",
    "        images.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the gallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) [default]",
   "language": "python",
   "name": "anaconda-project-default-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
